# token是什么

无论是编译型还是解释型语言，为了能够把编程语言转化为计算机能理解的内容，首先就要对用户输入的内容进行拆分，拆分的结果就是token。

## 词法分析器
词法分析器往往是编译或者解释的第一步，他将源代码抽象成为token序列。
词法分析器（lexer）也叫词法单元生成器（tokenizer）或者扫描器（scanner）。

### 词法分析器的功能
词法分析器是一些代码，它们能够实现这样的功能：把用户写的源代码，转换成一堆词法单元（token）。就像是你在翻译文言文的时候，首先需要把一句话拆分成为许多不可再分的单元，举个例子：你要翻译“庭有枇杷树”，首先就要把这句话拆分为 ["庭","有","枇杷","树"] 或者 ["庭","有","枇杷树"]。

对于一门像样的编程语言写的代码，例如下面的这一句：
```js
// 注意这不是任何一种已经存在的语言，只是我自己规定的假想象一种语言的语法，尽管他看上去有许多其他语言的影子
let x = 5 + 5;
```
我们得词法解析器应该能辨认出：
最开始有一个关键字let，然后是一个变量的名字x，后面是赋值符号=，加法符号+，还有数字5。
词法解析器应该按顺序给我们这样的结果

`[LET, IDENTIFIER('x'), EQUAL_SIGN, INTEGER(5), PLUS_SIGN, INTEGER(5)]`

这个结果中的每一个成员，都是一个词法单元token，每一个词法单元，都在源代码中有对应。

### 词法分析器的简单实现
朴素的想法就是把源代码当做字符串去扫描，正如“扫描器”这个名称暗示的那样。
这里我打算用一个小小的编程练习来引入：

1. 请写一段代码，每次能够读取字符串中的一个字符
2. 请写一段代码，能够识别 =+,;(){} 这些运算符和界限符
3. 完善2，能够识别关键字let,和标识符xyz, add, ...